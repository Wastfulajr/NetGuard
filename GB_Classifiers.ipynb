{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhaKdwKznXUh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import zipfile\n",
        "import numpy as np #working\n",
        "import io\n",
        "#This is me\n",
        "#THIS CODE JUST LOADS DATA INTO df\n",
        "# Download and load the dataset into one DataFrame\n",
        "dfs = []\n",
        "FILE_DOWNLOAD_URL = \"http://cicresearch.ca/CICDataset/CIC-IDS-2017/Dataset/CIC-IDS-2017/CSVs/GeneratedLabelledFlows.zip\"\n",
        "\n",
        "response = requests.get(FILE_DOWNLOAD_URL)\n",
        "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "    for file in z.namelist()[1:]:  # skip the first entry if it's a folder\n",
        "        with z.open(file) as f:\n",
        "            dfs.append(pd.read_csv(f, encoding='cp1252'))\n",
        "\n",
        "# Combine all CSVs into a single DataFrame\n",
        "df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap lightgbm imbalanced-learn xgboost\n"
      ],
      "metadata": {
        "id": "Z4y_BZkjQlpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, classification_report, confusion_matrix,\n",
        "    roc_curve, auc, precision_recall_curve, average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n"
      ],
      "metadata": {
        "id": "r8rUYZdjQmaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df, label_column=' Label'):\n",
        "    # Separate features and label\n",
        "    X = df.drop(columns=[label_column])\n",
        "    y = df[label_column]\n",
        "\n",
        "    # Keep numeric features\n",
        "    X = X.select_dtypes(include=['number'])\n",
        "\n",
        "    # Remove invalid values\n",
        "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    X.dropna(inplace=True)\n",
        "    y = y.loc[X.index]\n",
        "\n",
        "    # Encode string labels (BENIGN, DDoS, ...)\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "\n",
        "    return X, y_encoded, le\n"
      ],
      "metadata": {
        "id": "gDER4tcrQoS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    y_prob = model.predict_proba(X_test)\n",
        "\n",
        "    print(\"==== Classification Report ====\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"==== Confusion Matrix ====\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # Only for binary classification\n",
        "    if y_prob is not None and y_prob.shape[1] == 2:\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob[:, 1])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, label=f'AUC={roc_auc:.3f}')\n",
        "        plt.plot([0,1],[0,1],'k--')\n",
        "        plt.title(\"ROC Curve\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        precision, recall, _ = precision_recall_curve(y_test, y_prob[:, 1])\n",
        "        pr_auc = average_precision_score(y_test, y_prob[:, 1])\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(recall, precision, label=f'PR AUC={pr_auc:.3f}')\n",
        "        plt.title(\"Precision-Recall Curve\")\n",
        "        plt.xlabel(\"Recall\")\n",
        "        plt.ylabel(\"Precision\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    return y_pred\n"
      ],
      "metadata": {
        "id": "rEVts5PKQqHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_shap(model, X):\n",
        "explainer = shap.TreeExplainer(model)\n",
        "sample_size = min(2000, len(X))\n",
        "X_sample = X.sample(sample_size, random_state=42)\n",
        "\n",
        "shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "shap.summary_plot(shap_values, X_sample, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(shap_values, X_sample, show=True)"
      ],
      "metadata": {
        "id": "rSxI6A6RQr6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_multiclass_roc(model, X_test, y_test, class_names=None):\n",
        "    # Predict probabilities\n",
        "    y_score = model.predict_proba(X_test)\n",
        "\n",
        "    n_classes = y_score.shape[1]\n",
        "\n",
        "    # Binarize labels for multi-class ROC\n",
        "    y_test_bin = label_binarize(y_test, classes=list(range(n_classes)))\n",
        "\n",
        "    # Compute ROC curve and AUC per class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Compute ROC\n",
        "    # -------------------------\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in range(n_classes):\n",
        "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "    mean_tpr /= n_classes\n",
        "\n",
        "    macro_auc = auc(all_fpr, mean_tpr)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(all_fpr, mean_tpr, label=f\"Macro-average ROC (AUC = {macro_auc:.4f})\", linewidth=2)\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], \"k--\", linewidth=0.8)\n",
        "    plt.title(\"Multi-Class ROC Curve (Macro-Average)\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nPer-Class AUCs:\")\n",
        "    for i in range(n_classes):\n",
        "        cname = class_names[i] if class_names is not None else f\"Class {i}\"\n",
        "        print(f\"{cname}: AUC = {roc_auc[i]:.4f}\")"
      ],
      "metadata": {
        "id": "i0DvEzETT7Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(\n",
        "        X, y,\n",
        "        model=None,\n",
        "        use_smote=True,\n",
        "        test_size=0.2\n",
        "    ):\n",
        "\n",
        "    # Default model (XGBoost)\n",
        "    if model is None:\n",
        "        model = XGBClassifier(\n",
        "            random_state=42,\n",
        "            use_label_encoder=False,\n",
        "            eval_metric='logloss'\n",
        "        )\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    plot_multiclass_roc(reduced_model, X_test, y_test, class_names=label_encoder.classes_)\n",
        "\n",
        "    # SMOTE\n",
        "    if use_smote:\n",
        "        print(\"Applying SMOTE...\")\n",
        "        sm = SMOTE(random_state=42)\n",
        "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluation\n",
        "    evaluate_model(model, X_test, y_test)\n",
        "\n",
        "    # SHAP\n",
        "    run_shap(model, X_train)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "9sb_SrvKQq83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y_encoded, label_encoder = preprocess_data(df)\n",
        "\n",
        "\n",
        "model = train_model(X, y_encoded)\n",
        "\n",
        "# With SMOTE\n",
        "# model_smote = train_model(X, y_encoded, use_smote=True)\n"
      ],
      "metadata": {
        "id": "WXoHpry9QvZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def shap_feature_reduction_and_retrain(\n",
        "        X, y,\n",
        "        base_model=None,\n",
        "        drop_fraction=0.40,\n",
        "        smote=False,\n",
        "        shap_sample_size=2000\n",
        "    ):\n",
        "\n",
        "    print(\"\\n=== Training Baseline Model ===\")\n",
        "    # Train baseline model without feature reduction\n",
        "    baseline_model = train_model(X, y, model=base_model, use_smote=smote)\n",
        "\n",
        "    # Baseline evaluation\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "    baseline_pred = baseline_model.predict(X_test)\n",
        "    baseline_acc = accuracy_score(y_test, baseline_pred)\n",
        "\n",
        "    plot_multiclass_roc(baseline_model, X_test, y_test, class_names=label_encoder.classes_)\n",
        "\n",
        "    print(f\"\\nBaseline Accuracy: {baseline_acc:.4f}\")\n",
        "\n",
        "    print(\"\\n=== Computing SHAP Importances===\")\n",
        "    shap_sample_size = min(shap_sample_size, len(X_train))\n",
        "    X_sample, _, y_sample, _ = train_test_split(\n",
        "        X_train, y_train,\n",
        "        train_size=shap_sample_size,\n",
        "        stratify=y_train,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    explainer = shap.TreeExplainer(baseline_model)\n",
        "    shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "    # There was a shape issue this seems to fix\n",
        "    shap_importance = np.ravel(shap_importance)\n",
        "\n",
        "    # Build importance DataFrame\n",
        "    importance_df = pd.DataFrame({\n",
        "        \"feature\": X_sample.columns,\n",
        "        \"shap_importance\": shap_importance\n",
        "    }).sort_values(\"shap_importance\", ascending=False)\n",
        "\n",
        "    # Drop low importance features\n",
        "    n_features = len(importance_df)\n",
        "    n_drop = int(n_features * drop_fraction)\n",
        "    to_drop = importance_df.tail(n_drop)[\"feature\"].tolist()\n",
        "\n",
        "    print(f\"\\nDropping lower {drop_fraction*100:.0f}% ({n_drop}) SHAP features:\")\n",
        "    for f in to_drop:\n",
        "        print(\" -\", f)\n",
        "\n",
        "    X_reduced = X.drop(columns=to_drop)\n",
        "    print(f\"\\nReduced feature count: {X_reduced.shape[1]} (was {X.shape[1]})\")\n",
        "\n",
        "    # Retrain model with reduced feature set\n",
        "    print(\"\\n=== Training Reduced-Feature Model ===\")\n",
        "    reduced_model = train_model(X_reduced, y, model=base_model, use_smote=smote)\n",
        "\n",
        "    # Evaluate reduced model\n",
        "    X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
        "        X_reduced, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    reduced_pred = reduced_model.predict(X_test_r)\n",
        "    reduced_acc = accuracy_score(y_test_r, reduced_pred)\n",
        "\n",
        "    plot_multiclass_roc(reduced_model, X_test_r, y_test_r, class_names=label_encoder.classes_)\n",
        "\n",
        "    print(f\"\\nReduced Accuracy: {reduced_acc:.4f}\")\n",
        "\n",
        "    # Report comparison\n",
        "    print(\"\\n=== Performance Comparison Report ===\")\n",
        "    print(f\"Baseline Accuracy: {baseline_acc:.4f}\")\n",
        "    print(f\"Reduced  Accuracy: {reduced_acc:.4f}\")\n",
        "\n",
        "    if reduced_acc > baseline_acc:\n",
        "        print(\"\\n Performance IMPROVED\")\n",
        "    elif reduced_acc == baseline_acc:\n",
        "        print(\"\\n Performance UNCHANGED.\")\n",
        "    else:\n",
        "        print(\"\\n Performance DROPPED.\")\n",
        "\n",
        "    return {\n",
        "        \"baseline_accuracy\": baseline_acc,\n",
        "        \"reduced_accuracy\": reduced_acc,\n",
        "        \"dropped_features\": to_drop,\n",
        "        \"importance_dataframe\": importance_df,\n",
        "        \"baseline_model\": baseline_model,\n",
        "        \"reduced_model\": reduced_model\n",
        "    }\n",
        "\n",
        "results = shap_feature_reduction_and_retrain(X, y_encoded)\n"
      ],
      "metadata": {
        "id": "FRgXEcickOGY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}